{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and process\n",
    "\n",
    "This notebook shows the use of the functions in the `subject.py` module. They are functions that deal with loading and calibrating data \n",
    "from a single subject, cutting the data into trials, and then getting a measure of success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T13:35:24.132279400Z",
     "start_time": "2024-01-16T13:35:17.697683600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import sem\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation as animation\n",
    "from matplotlib.widgets import Slider\n",
    "\n",
    "# importing functions from our projects py files\n",
    "module_path = os.path.abspath(os.path.join('..')) # the path to the source code\n",
    "sys.path.insert(0, module_path)\n",
    "\n",
    "from markers_analysis import constants as consts\n",
    "from markers_analysis import subject as subj\n",
    "from markers_analysis import billiards_table as billiards\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T13:35:24.321878500Z",
     "start_time": "2024-01-16T13:35:24.136279700Z"
    }
   },
   "outputs": [],
   "source": [
    "# ???\n",
    "mpl.rcParams.update({'font.size': 14})\n",
    "\n",
    "%matplotlib widget  \n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The regular expression\n",
    "\n",
    "The code for finding the appropriate regular expression in the `subject.py` module was built using [Regular Expression 101](https://regex101.com/). \n",
    "\n",
    "Actually, after that I needed a little help from ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T13:35:24.338045500Z",
     "start_time": "2024-01-16T13:35:24.325257700Z"
    }
   },
   "outputs": [],
   "source": [
    "results_path = os.path.join('.', 'pkl')\n",
    "fig_path = os.path.join('.', 'img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T13:35:24.341430100Z",
     "start_time": "2024-01-16T13:35:24.333441200Z"
    }
   },
   "outputs": [],
   "source": [
    "basename = 'white_ball_hit '\n",
    "subject_id_list = ['007', '008', '009', '010', '011', '012', '013', '014']\n",
    "date_list = ['2023_11_20', '2023_11_20', '2023_11_20', '2023_12_03', '2023_12_03', '2023_12_03', '2023_12_14', '2023_12_14']\n",
    "\n",
    "# subject_id_list = ['012', '013', '014']\n",
    "# date_list = ['2023_12_03', '2023_12_14', '2023_12_14']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remapping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-16T13:35:24.388373700Z",
     "start_time": "2024-01-16T13:35:24.347765Z"
    }
   },
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    \"white_ball\": \"cue_ball\",\n",
    "    \"purple_ball\": \"object_ball\",\n",
    "    \"red_ball\": \"target_ball\",\n",
    "    \"cue_mid\": \"start_cue\",\n",
    "    \"cue_tip\": \"end_cue\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-16T13:35:24.366417100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PerformanceWarning [C:\\Users\\noamg\\OneDrive - post.bgu.ac.il\\Documents\\motor learning lab\\GitHub\\Noam-markers-analysis\\markers_analysis\\subject.py:117] dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ..\\data\\subject_007\\2023_11_20\\table\\white_ball_hit 1_video4DLC_resnet50_purple objectNov8shuffle1_200000.h5\n",
      "  Results returned in pixels\n",
      "pixel_coords=[array([ 40.41199149, 142.40061707]), array([ 67.47350378, 143.3311501 ]), array([ 94.23731636, 144.30615744]), array([120.1031982 , 145.16072987]), array([ 24.50786529, 120.47332676]), array([26.38408262, 83.60748862]), array([136.06664908, 125.10479049]), array([136.23466782, 106.49962615]), array([135.94942888,  88.94708557]), array([43.69408282, 64.70350371]), array([70.10664092, 66.59071528]), array([95.37269991, 67.45593823]), array([120.38531098,  68.95852854])]\n",
      "real_coords=\n",
      "\n",
      "  Table calibrated with an error of 0.331 cm\n",
      "************* Done with subject f007 file number 1: ..\\data\\subject_007\\2023_11_20\\table\\white_ball_hit 1_video4DLC_resnet50_purple objectNov8shuffle1_200000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PerformanceWarning [C:\\Users\\noamg\\OneDrive - post.bgu.ac.il\\Documents\\motor learning lab\\GitHub\\Noam-markers-analysis\\markers_analysis\\subject.py:117] dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ..\\data\\subject_007\\2023_11_20\\table\\white_ball_hit 2_video4DLC_resnet50_purple objectNov8shuffle1_200000.h5\n",
      "  Results returned in pixels\n",
      "pixel_coords=[array([ 40.39713104, 142.39675764]), array([ 67.47761155, 143.35494839]), array([ 94.2395845 , 144.35229191]), array([120.11841693, 145.29954208]), array([ 24.48771717, 120.50534175]), array([26.34521655, 83.62137014]), array([136.07692594, 125.21448169]), array([136.1907426 , 106.64823699]), array([135.87270631,  88.97478756]), array([43.64674573, 64.72453448]), array([70.10387246, 66.6043267 ]), array([95.26561408, 67.37447814]), array([120.23761313,  69.18994833])]\n",
      "real_coords=\n",
      "\n",
      "  Table calibrated with an error of 0.343 cm\n",
      "************* Done with subject f007 file number 2: ..\\data\\subject_007\\2023_11_20\\table\\white_ball_hit 2_video4DLC_resnet50_purple objectNov8shuffle1_200000.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PerformanceWarning [C:\\Users\\noamg\\OneDrive - post.bgu.ac.il\\Documents\\motor learning lab\\GitHub\\Noam-markers-analysis\\markers_analysis\\subject.py:117] dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "for subject_id, date in zip(subject_id_list, date_list):\n",
    "    calibrated_file_name = os.path.join(results_path, f'id{subject_id} calibrated.pkl')\n",
    "\n",
    "    if os.path.exists(calibrated_file_name):\n",
    "        # File exists, unpickle the data\n",
    "        with open(calibrated_file_name, 'rb') as file:\n",
    "            subject_data = pickle.load(file)\n",
    "    else:\n",
    "        # Process the file\n",
    "        subject_data = {}\n",
    "\n",
    "        info = {}\n",
    "        info['id'] = subject_id\n",
    "        info['date'] = date\n",
    "        info['basename'] = basename\n",
    "        subject_data['info'] = info\n",
    "        subject_data['data'] = []\n",
    "\n",
    "        for filenum,filename in subj.find_ball_data_files(date=info['date'], id=subject_id, basename='white_ball_hit '):\n",
    "            data_dict_pixels = subj.load_ball_data_file(filename, column_mapping=column_mapping, calibrate_table=False)\n",
    "            # data_dict_for_video = copy.deepcopy(data_dict_pixels)\n",
    "            # end_video_time = np.min([30, data_dict_for_video['ts'].time[-1]])\n",
    "            # start_video_time = np.max([0, end_video_time-15])\n",
    "            # data_dict_for_video['ts'] = data_dict_for_video['ts'].get_ts_between_times(start_video_time, end_video_time)\n",
    "            # video_file = f'pixels {subject_id} {filenum}.mp4'\n",
    "            # billiards.create_video(data_dict_for_video, video_file, do_dots=True, xlims=[0, 220], ylims=[0, 220], keep_time=[10, 20])\n",
    "\n",
    "            data_dict = subj.calibrate_table(data_dict_pixels)\n",
    "            # data_dict_for_video = copy.deepcopy(data_dict)\n",
    "            # data_dict_for_video['ts'] = data_dict_for_video['ts'].get_ts_between_times(start_video_time, end_video_time)\n",
    "            # video_file = f'calibrated {subject_id} {filenum}.mp4'\n",
    "            # billiards.create_video(data_dict_for_video, video_file, do_dots=True, xlims=[0, 220], ylims=[0, 220], keep_time=[10, 20])\n",
    "\n",
    "            data_dict['filenum'] = filenum\n",
    "            data_dict['filename'] = filename\n",
    "            subject_data['data'].append(data_dict)\n",
    "            print(f\"************* Done with subject f{subject_data['info']['id']} file number {subject_data['data'][-1]['filenum']}: {subject_data['data'][-1]['filename']}\")\n",
    "\n",
    "        with open(calibrated_file_name, 'wb') as file:\n",
    "            pickle.dump(subject_data, file)\n",
    "\n",
    "    all_data.append(subject_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate velocity and speed\n",
    "It is pretty easy to add new calculations based on the underlying function `subj.get_calculated_data` which runs over all the data and adds a calculation.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "for subject_data in all_data:\n",
    "    updated_data_dicts = []\n",
    "    for data_dict in subject_data['data']:\n",
    "        ts = data_dict[\"ts\"]\n",
    "        ball_names = [k for k, v in ts.data_info.items() if v[\"Type\"] == \"Ball\"]\n",
    "\n",
    "        balls = ts.get_subset(ball_names)\n",
    "        subj.get_velocities(balls, merge_in_place=True)\n",
    "        subj.get_speeds(balls, merge_in_place=True)\n",
    "        subj.get_moving(balls, merge_in_place=True)\n",
    "        ts.merge(balls, in_place=True, overwrite=False)\n",
    "\n",
    "        data_dict[\"ts\"] = ts\n",
    "        updated_data_dicts.append(data_dict)\n",
    "\n",
    "    subject_data['data'] = updated_data_dicts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut the data\n",
    "These section take the long stream of data and identifies the beginning and end of shots and generates a list of time series with the data from each shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "all_cut_data = []\n",
    "\n",
    "for subject_data in all_data:\n",
    "    subject_id = subject_data['info']['id']\n",
    "    cut_filename = os.path.join(results_path, f'id{subject_id} cut.pkl') \n",
    "\n",
    "    if os.path.exists(cut_filename):\n",
    "        # File exists, unpickle the data\n",
    "        with open(cut_filename, 'rb') as file:\n",
    "            shots_data = pickle.load(file)\n",
    "    else:\n",
    "        shots_data = {}\n",
    "        shots_data['info'] = subject_data['info']\n",
    "        shots_data['shots'] = []\n",
    "\n",
    "        for data_dict in subject_data['data']:\n",
    "            shot_times = subj.get_shots(data_dict)\n",
    "\n",
    "            for shotnum, shotrow in shot_times.iterrows():\n",
    "                start_time = shotrow.start_time\n",
    "                end_time = shotrow.end_time\n",
    "                shot_ts = data_dict['ts'].get_ts_between_times(start_time, end_time, inclusive=True)\n",
    "                # Set 0 time to the moment the shot actually starts\n",
    "                zero_time = shot_ts.time[0]+consts.start_positions_time\n",
    "                shot_ts.shift(-zero_time, in_place=True) \n",
    "                \n",
    "                shot_data = {}\n",
    "                shot_data['filenum'] = data_dict['filenum']\n",
    "                shot_data['shotnum'] = shotnum\n",
    "                shot_data['start_time'] = start_time\n",
    "                shot_data['zero_time'] = zero_time\n",
    "                shot_data['end_time'] = end_time\n",
    "                shot_data['table'] = data_dict['table']\n",
    "                shot_data['ts'] = shot_ts\n",
    "                \n",
    "                shots_data['shots'].append(shot_data)\n",
    "    \n",
    "        with open(cut_filename, 'wb') as file:\n",
    "            pickle.dump(shots_data, file)      \n",
    "\n",
    "\n",
    "    all_cut_data.append(shots_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "ax = None\n",
    "for shots_data in all_cut_data:\n",
    "    subject_id = shots_data['info']['id']\n",
    "    hits = []\n",
    "    num_shots = len(shots_data['shots'])\n",
    "    bin_width = 30\n",
    "    num_bins = num_shots - bin_width\n",
    "    bin_start = np.arange(0, num_bins)\n",
    "    bin_stop = np.arange(bin_width, num_shots)\n",
    "    bin_middle = (bin_start + bin_stop) / 2\n",
    "    bin_hits = np.full_like(bin_start, 0)\n",
    "\n",
    "    for start, stop in zip(bin_start, bin_stop):\n",
    "        bin_shots = shots_data['shots'][start:stop]\n",
    "        bin_hits[start] = subj.count_hits(bin_shots)\n",
    "\n",
    "\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots()\n",
    "    else:\n",
    "        ax.clear()\n",
    "\n",
    "    ax.set_xlim([0, 200])\n",
    "    ax.plot(bin_middle, bin_hits)\n",
    "    ax.set_ylabel('Hits')\n",
    "    ax.set_xlabel('Shot')\n",
    "    ax.set_title(f'Subject {subject_id} successes (bin width: {bin_width})')\n",
    "\n",
    "    fig_savename = os.path.join(fig_path, f\"successes {subject_id}.png\")\n",
    "    plt.savefig(fig_savename)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angular error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the angular error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot absolute angular error learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "ax = None\n",
    "for shots_data in all_cut_data:\n",
    "    subject_id = shots_data['info']['id']\n",
    "\n",
    "    angles = subj.get_angles(shots_data['shots'])\n",
    "    hits = subj.is_hit(shots_data['shots'])\n",
    "\n",
    "    # Concatenate the arrays into one long 1D array\n",
    "    # angles_deg = np.abs(angles * 180 / np.pi)\n",
    "    angles_deg = np.abs(angles * 180 / np.pi)\n",
    "\n",
    "    # Remove the big outliers\n",
    "    outliers = (angles_deg < -60) | (angles_deg > 60)\n",
    "    angles_deg[outliers] = np.nan\n",
    "\n",
    "    # Interpolate over NaN values\n",
    "    nan_indices = np.isnan(angles_deg)\n",
    "    interp_angles = angles_deg.copy()\n",
    "    interp_angles[nan_indices] = np.interp(\n",
    "        np.flatnonzero(nan_indices),\n",
    "        np.flatnonzero(~nan_indices),\n",
    "        angles_deg[~nan_indices])\n",
    "\n",
    "    # Define the exponential function\n",
    "    def exponential_function(x, a, b, c):\n",
    "        return a * np.exp(-b * x) + c\n",
    "\n",
    "    # Define a function to fit exponential function with NaN values\n",
    "    def fit_exponential_with_nans(x, y):\n",
    "        # Filter out NaN values\n",
    "        valid_indices = ~np.isnan(y)\n",
    "        x_valid = x[valid_indices]\n",
    "        y_valid = y[valid_indices]\n",
    "\n",
    "        # Perform the exponential fit\n",
    "        try:\n",
    "            params, _ = curve_fit(exponential_function, x_valid, y_valid)\n",
    "        except RuntimeError:\n",
    "            params = [np.nan, np.nan, np.nan]\n",
    "\n",
    "        # Create the fitted curve including NaN values\n",
    "        fitted_curve = exponential_function(x, *params)\n",
    "\n",
    "        return fitted_curve\n",
    "\n",
    "    # Generate an x array (assuming your data is evenly spaced)\n",
    "    x = np.arange(len(angles_deg))\n",
    "\n",
    "    \n",
    "    training_epoch = x >= 15\n",
    "\n",
    "    # Perform the exponential fit with NaN values\n",
    "    exponential_fit = fit_exponential_with_nans(x[training_epoch], angles_deg[training_epoch])\n",
    "\n",
    "    # Plot the original data and fit\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(figsize=(21/2.54, 7/2.54))\n",
    "    else:\n",
    "        ax.clear()\n",
    "\n",
    "    # hit_colors = np.where(hits, 'red', 'blue')\n",
    "    hits = np.array(hits)\n",
    "    shot_number = np.arange(len(angles_deg))\n",
    "\n",
    "    ax.plot(shot_number[training_epoch], angles_deg[training_epoch], 'bo', label='Angular error')\n",
    "    ax.plot(shot_number[hits & training_epoch], angles_deg[hits & training_epoch], 'ro', label='Success')\n",
    "    ax.plot(shot_number[~training_epoch], angles_deg[~training_epoch], 'o', color='grey')\n",
    "    ax.axvspan(xmin=0, xmax=15, color='#D2B48C', alpha=0.3, label='Baseline')\n",
    "\n",
    "            \n",
    "    ax.plot(shot_number[training_epoch], exponential_fit, 'b-', linewidth=2)\n",
    "    ax.set_ylim([-20, 75])\n",
    "    ax.set_xlim([0, 200])\n",
    "    ax.set_title(f'Subject {subject_id}: Absolute angular error')\n",
    "    ax.set_xlabel('Shot')\n",
    "    ax.set_ylabel('$|Error|$ (deg)')\n",
    "\n",
    "    ax.legend(loc='upper right') #, bbox_to_anchor=(1.25, 1))\n",
    "\n",
    "    fig_savename = os.path.join(fig_path, f\"error {subject_id}.png\")\n",
    "    plt.savefig(fig_savename, bbox_inches='tight')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import markers_analysis\n",
    "\n",
    "importlib.reload(markers_analysis)\n",
    "importlib.reload(markers_analysis.constants)\n",
    "importlib.reload(markers_analysis.subject)\n",
    "importlib.reload(markers_analysis.billiards_table)\n",
    "importlib.reload(markers_analysis.math)\n",
    "importlib.reload(consts)\n",
    "importlib.reload(billiards)\n",
    "importlib.reload(subj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make average learning plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data for all subjects into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "angles_list = []\n",
    "hits_list = []\n",
    "\n",
    "for shots_data in all_cut_data:\n",
    "    subject_id = shots_data['info']['id']\n",
    "\n",
    "    angles = subj.get_angles(shots_data['shots'])\n",
    "    hits = subj.is_hit(shots_data['shots'])\n",
    "\n",
    "    # Concatenate the arrays into one long 1D array\n",
    "    # angles_deg = np.abs(angles * 180 / np.pi)\n",
    "    angles_deg = angles * 180 / np.pi\n",
    "\n",
    "    # Remove the big outliers\n",
    "    outliers = (angles_deg < -60) | (angles_deg > 60)\n",
    "    angles_deg[outliers] = np.nan\n",
    "\n",
    "    # Interpolate over NaN values\n",
    "    nan_indices = np.isnan(angles_deg)\n",
    "    interp_angles = angles_deg.copy()\n",
    "    interp_angles[nan_indices] = np.interp(\n",
    "        np.flatnonzero(nan_indices),\n",
    "        np.flatnonzero(~nan_indices),\n",
    "        angles_deg[~nan_indices]\n",
    "    )\n",
    "\n",
    "    angles_list.append(angles_deg)\n",
    "    hits_list.append(hits)\n",
    "\n",
    "angles_df = pd.DataFrame(angles_list)\n",
    "hits_df = pd.DataFrame(hits_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from statsmodels.robust import mad\n",
    "\n",
    "num_subj = angles_df.shape[0]\n",
    "\n",
    "# Replace NaN with median for MAD calculation\n",
    "angles_no_nan = angles_df.apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "\n",
    "# Calculate median and Median Absolute Deviation (MAD) for each shot\n",
    "median_angles = -angles_df.median(axis=0, skipna=True)\n",
    "mad_angles = mad(angles_no_nan, axis=0, center=np.median)\n",
    "\n",
    "# Convert mad_angles to a Pandas Series\n",
    "mad_series = pd.Series(mad_angles, index=median_angles.index)\n",
    "\n",
    "# Smooth the SEM using a rolling window average\n",
    "window_size = 10  # Adjust the window size as needed\n",
    "smoothed_median = median_angles.rolling(window=window_size, min_periods=1, center=True).mean()\n",
    "smoothed_sem = mad_series.rolling(window=window_size, min_periods=1, center=True).mean()\n",
    "\n",
    "# Fill NaN values at the edges caused by rolling window\n",
    "smoothed_median = smoothed_median.interpolate(method='linear')\n",
    "smoothed_sem = smoothed_sem.interpolate(method='linear')\n",
    "\n",
    "\n",
    "# Calculate percentage of hits for each shot\n",
    "percentage_hits = hits_df.mean(axis=0, skipna=True)\n",
    "\n",
    "# Bin the percentage hits into discrete bins\n",
    "num_bins = 5\n",
    "bins = pd.cut(percentage_hits, bins=num_bins, labels=False, retbins=True)[1]\n",
    "\n",
    "# Map each shot to a color based on the percentage hits\n",
    "RGB = lambda p,b: ((1-b)*p + b, -b*p+b, -b*p+b)\n",
    "color_dict = {shot: RGB(percentage_hit, 0.5) for shot, percentage_hit in percentage_hits.items()}\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(1.2*21/2.54, 1.2*1.2*7/2.54))\n",
    "\n",
    "# Plot shaded patch for smoothed SEM\n",
    "x_vals = np.arange(len(smoothed_median))\n",
    "sem_handle = ax.fill_between(x_vals, smoothed_median - smoothed_sem, smoothed_median + smoothed_sem, alpha=0.6, color='darkgray', label='Smoothed median +/- SEM')\n",
    "\n",
    "# Plot markers with colored shading based on percentage of hits for each shot\n",
    "for shot, percentage_hit in percentage_hits.items():\n",
    "    if shot >= 15:\n",
    "        color = color_dict[shot]\n",
    "            \n",
    "    else:\n",
    "        color = 'k'\n",
    "    line_handle = ax.scatter(shot, median_angles[shot], color=color, s=50)\n",
    "\n",
    "    if shot < 15:\n",
    "        median_handle = line_handle\n",
    "    if shot >= 15: \n",
    "        if percentage_hit == np.max(percentage_hits):\n",
    "            max_label_handle = line_handle\n",
    "            max_percentage_val = round(percentage_hit*100, -1)\n",
    "        elif percentage_hit == np.min(percentage_hits):\n",
    "            min_label_handle = line_handle            \n",
    "            min_percentage_val = round(percentage_hit*100, -1)\n",
    "\n",
    "median_handle.set_label(f'Median (N={num_subj})')            \n",
    "max_label_handle.set_label(f'{max_percentage_val:.0f}% hits')\n",
    "min_label_handle.set_label(f'{min_percentage_val:.0f}% hits')\n",
    "\n",
    "\n",
    "baseline_handle = ax.axvspan(xmin=0, xmax=15, color='#D2B48C', alpha=0.3, label='Baseline')\n",
    "plt.axhline(0, color='black', linestyle='--', dashes=(8,4))\n",
    "\n",
    "# Add custom legend lines using handles\n",
    "legend_handles = [\n",
    "    median_handle,\n",
    "    min_label_handle,\n",
    "    max_label_handle,\n",
    "    sem_handle,\n",
    "    baseline_handle\n",
    "]\n",
    "\n",
    "ax.set_xlim(0, 200)\n",
    "ax.set_ylim(-15, 50)\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel('Shot')\n",
    "ax.set_ylabel('Angular Error')\n",
    "# ax.set_title('Median Angular Error with MAD and Marker Color Based on Percentage of Hits for Each Shot')\n",
    "ax.legend(handles=legend_handles, loc='upper right', bbox_to_anchor=(1, 1.2))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_savename = os.path.join(fig_path, f\"median error.png\")\n",
    "plt.savefig(fig_savename, bbox_inches='tight', dpi=600)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Convert mad_angles to a Pandas Series\n",
    "mad_series = pd.Series(mad_angles, index=median_angles.index)\n",
    "\n",
    "# Smooth the SEM using a rolling window average\n",
    "window_size = 3  # Adjust the window size as needed\n",
    "smoothed_sem = mad_series.rolling(window=window_size, min_periods=1, center=True).mean()\n",
    "\n",
    "# Fill NaN values at the edges caused by rolling window\n",
    "smoothed_sem = smoothed_sem.interpolate(method='linear')\n",
    "\n",
    "smoothed_sem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ktk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
